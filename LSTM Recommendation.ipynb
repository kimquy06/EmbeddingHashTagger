{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_no_hashtag_symbols.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_document = \" \".join([tweet[\"text\"] for tweet in data])\n",
    "global_document = re.sub(r\"\\s+\", \" \", global_document).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_hts(tweets):\n",
    "    all_hts = []\n",
    "    count = {}\n",
    "    for tweet in tweets:\n",
    "        for ht in tweet[\"hashtags\"]:\n",
    "            if ht.lower() in count:\n",
    "                count[ht.lower()] = count[ht.lower()] + 1\n",
    "            else:\n",
    "                count[ht.lower()] = 1\n",
    "            all_hts.append(ht.lower())\n",
    "    return all_hts, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_hts, count = get_all_hts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_some(count):\n",
    "    hts = []\n",
    "    for key, value in count.items():\n",
    "        if value > 200 and value < 500:\n",
    "            hts.append(key)\n",
    "    return hts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_hts = set(filter_some(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_hts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86660"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_hts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(data, all_hts):\n",
    "    global_document = \" \".join([tweet[\"text\"] for tweet in data])\n",
    "    global_document = re.sub(r\"\\s+\", \" \", global_document).strip()\n",
    "    words = global_document.split(\" \")\n",
    "    vocab = {}\n",
    "    hts_vocab = {}\n",
    "    for tweet in data:\n",
    "        for ht in tweet[\"hashtags\"]:\n",
    "            if ht.lower() not in hts_vocab:\n",
    "                hts_vocab[ht.lower()] = len(hts_vocab)\n",
    "                \n",
    "    for word in words:\n",
    "        if word.lower() not in vocab:\n",
    "            vocab[word.lower()] = len(vocab)\n",
    "    reversed_vocab = dict(zip(vocab.values(), vocab.keys()))\n",
    "    reversed_hts_vocab = dict(zip(hts_vocab.values(), hts_vocab.keys()))\n",
    "    return vocab, reversed_vocab, hts_vocab, reversed_hts_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab, reversed_vocab, ht_vocab, reversed_ht_vocab = build_vocab(data, all_hts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ht_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reversed_ht_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_tweets(data, vocab, ht_vocab):\n",
    "    tweet_new = []\n",
    "    for tweet in data:\n",
    "        new_hts = []\n",
    "        for ht in tweet[\"hashtags\"]:\n",
    "            if ht.lower() in ht_vocab:\n",
    "                new_hts.append(ht_vocab[ht.lower()])\n",
    "        words = tweet[\"text\"].split(\" \")\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                new_words.append(vocab[word])\n",
    "        if new_words != [] and new_hts != []:\n",
    "            tweet_new.append({\"text\": new_words, \"hashtags\": new_hts})\n",
    "    return tweet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_encoded = map_tweets(data, vocab, ht_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [3426, 2235],\n",
       " 'text': [2927, 2928, 336, 18, 19, 2801, 8664, 593, 2348, 1254, 55, 5507]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_encoded[87364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_continuous(encoded_ls):\n",
    "    cont = []\n",
    "    for encoded in encoded_ls:\n",
    "        for ht in encoded[\"hashtags\"]:\n",
    "            for word in encoded[\"text\"]:\n",
    "                    cont.append((word, ht))\n",
    "#                     break\n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_continuous = make_continuous(tweets_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7643678"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, n_classes):\n",
    "    y_cat = np.zeros((len(y), n_classes), dtype=np.int32)\n",
    "#     print(y_cat.shape)\n",
    "    y_cat[np.arange(len(y)), y] = 1\n",
    "    return y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical([10, 11], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thalv\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_twi = gensim.models.KeyedVectors.load_word2vec_format('word2vec_twitter_model.bin', binary=True, unicode_errors=\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_ids_to_embedding(word_ids, reversed_vocab, model):\n",
    "    words = [reversed_vocab[word_id] for word_id in word_ids]\n",
    "    word_embeddings = []\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            word_embeddings.append(model.wv[word])\n",
    "        else:\n",
    "            word_embeddings.append(np.average(model.wv[list(model.wv.vocab.keys())], axis=0))\n",
    "    return np.array(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, n_htags, reversed_vocab, model, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.n_htags = n_htags\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "        self.skip_step = skip_step\n",
    "        self.reversed_vocab = reversed_vocab\n",
    "        self.model = model\n",
    "        \n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps, 400))\n",
    "        y = np.zeros((self.batch_size, self.num_steps, self.n_htags))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                x[i, :] = word_ids_to_embedding(list(map(lambda x: x[0], self.data[self.current_idx:self.current_idx + self.num_steps])), self.reversed_vocab, self.model) \n",
    "                temp_y = list(map(lambda x: x[1], self.data[self.current_idx:self.current_idx + self.num_steps ]))\n",
    "                # convert all of temp_y into a one hot representation\n",
    "                y[i, :, :] = to_categorical(temp_y, n_classes=self.n_htags)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(tweets_continuous)\n",
    "train_data = tweets_continuous[:int(len(tweets_continuous) * 0.7)]\n",
    "test_data = tweets_continuous[int(len(tweets_continuous)* 0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "batch_size = 50\n",
    "n_htags = len(ht_vocab)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, n_htags, reversed_vocab, model_twi,\n",
    "                                           skip_step=num_steps)\n",
    "valid_data_generator = KerasBatchGenerator(test_data, num_steps, batch_size, n_htags, reversed_vocab, model_twi, \n",
    "                                           skip_step=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Embedding, Dropout, TimeDistributed, Flatten\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103905"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_htags = len(ht_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(len(vocab), 50, input_length=num_steps))\n",
    "# model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(20, input_shape=(num_steps, 400), return_sequences=True))\n",
    "# if use_dropout:\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(n_htags))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models\" + '/model-{epoch:02d}.hdf5', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thalv\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\ipykernel\\__main__.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "C:\\Users\\thalv\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "C:\\Users\\thalv\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\ipykernel\\__main__.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_data_generator.generate(), len(train_data)//(batch_size*num_steps), num_epochs,\n",
    "                        validation_data=valid_data_generator.generate(),\n",
    "                        validation_steps=len(test_data)//(batch_size*num_steps), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word 2 vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_hts(tweets):\n",
    "    all_hts = []\n",
    "    for tweet in tweets:\n",
    "        all_hts.extend(tweet[\"hashtags\"])\n",
    "    return all_hts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_document_per_ht(tweets):\n",
    "    hts_to_doc = {}\n",
    "    for tweet in tweets:\n",
    "        for hts in tweet[\"hashtags\"]:\n",
    "            if hts.lower() in hts_to_doc:\n",
    "                hts_to_doc[hts.lower()] = hts_to_doc[hts.lower()] + \" \" + tweet[\"text\"]\n",
    "            else:\n",
    "                hts_to_doc[hts.lower()] = tweet[\"text\"]\n",
    "    return hts_to_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_whitespaces(hts_to_doc):\n",
    "    hts_to_doc_new = {}\n",
    "    for key, value in hts_to_doc.items():\n",
    "        hts_to_doc_new[key] = re.sub(r\"\\s+\", \" \", value).strip()\n",
    "    return hts_to_doc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thalv\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = global_document.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_wv = gensim.models.Word2Vec(min_count=5, size=embedding_size, workers=4, window=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_wv.build_vocab([sentences])  # can be a non-repeatable, 1-pass generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000000, 2914388000)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.train([sentences], epochs=2000, total_examples=len(sentences)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ht_embedding(model, ht_to_doc):\n",
    "    ht_to_embedding = {}\n",
    "    for ht, doc in ht_to_doc.items():\n",
    "        words = doc.split(\" \")\n",
    "        words_in_model = [word for word in words if word in model.wv]\n",
    "        if words_in_model != []:\n",
    "            embeddings = model.wv[words_in_model]\n",
    "            ht_to_embedding[ht] = np.average(embeddings, axis=0)\n",
    "    return ht_to_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hts_to_doc = create_document_per_ht(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hts_to_doc = remove_whitespaces(hts_to_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isforsal'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts_to_doc[\"morale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht_to_embedding = create_ht_embedding(model, hts_to_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_of_tweet(tweet, model):\n",
    "    words = tweet[\"text\"].split(\" \")\n",
    "    words_in_model = [word for word in words if word in model.wv]\n",
    "    if words_in_model != []:\n",
    "        return np.average(model.wv[words_in_model], axis=0)\n",
    "    else:\n",
    "        return np.average(model.wv[list(model.wv.vocab.keys())], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_set(tweets, ht_to_embeddings, model):\n",
    "    X, y = [], []\n",
    "    for tweet in tweets:\n",
    "        tweet_embedding = get_embedding_of_tweet(tweet, model)\n",
    "        for ht in tweet[\"hashtags\"]:\n",
    "            if ht.lower() in ht_to_embedding:\n",
    "                X.append(tweet_embedding)\n",
    "                y.append(ht_to_embedding[ht.lower()])\n",
    "                break\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_set_one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_copy = data[:]\n",
    "np.random.shuffle(data_copy)\n",
    "train_data = data_copy[:int(len(data_copy) * 0.7)]\n",
    "test_data = data_copy[int(len(data_copy)* 0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = get_set(train_data, ht_to_embedding, model_wv)\n",
    "test_ds = get_set(test_data, ht_to_embedding, model_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_ds\n",
    "X_test, y_test = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_tweets_embeds(tweets, model):\n",
    "    out = np.ndarray(shape=(len(tweets), embedding_size))\n",
    "    i = 0\n",
    "    for tweet in tweets:\n",
    "        out[i] = get_embedding_of_tweet(tweet, model)\n",
    "        i += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_embeds = get_all_tweets_embeds(test_data, model_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64854, 100)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05372949,  0.23699877, -0.72665703,  0.20959198, -0.37921444,\n",
       "         0.03314155,  0.6936641 , -0.0411706 ,  0.51279944, -0.17726114,\n",
       "         0.10804163,  0.24417205,  0.32177594,  0.6527193 , -0.00435733,\n",
       "        -0.43116927,  0.19104266,  0.2960647 ,  0.3152053 , -0.37343585,\n",
       "         0.01361017, -0.5840937 , -0.14027278,  0.0232118 ,  0.2142771 ,\n",
       "         0.74627733, -0.24635406,  0.2243491 , -0.1679705 , -0.4126753 ,\n",
       "         0.78151166, -0.63271   , -0.77929133, -0.57505333, -0.7550303 ,\n",
       "        -0.26527995, -0.37601975, -0.20180313, -0.44537887, -0.6992404 ,\n",
       "        -0.47454947,  0.45448953,  0.30768076, -0.05988231, -0.03970312,\n",
       "        -0.05408294,  0.05286335, -0.04831612,  1.1823    ,  0.42542905,\n",
       "         0.05556975, -0.3030563 , -0.17094271,  0.0597505 , -0.3027652 ,\n",
       "        -0.16452956,  0.305381  , -0.3359519 , -1.1972561 ,  0.07526033,\n",
       "         0.01893089,  0.8890578 , -0.05066783, -0.58174855, -0.66157156,\n",
       "         0.27091426,  0.6592773 ,  0.25566757,  0.9800252 ,  0.419001  ,\n",
       "         0.5553136 , -0.04743644, -0.15794566, -0.8675598 , -0.08308289,\n",
       "         0.02384625,  0.42876607,  0.31623664, -0.12228873,  0.19895856,\n",
       "         0.00900458, -0.35655567,  0.18024068, -0.6736576 ,  0.3053822 ,\n",
       "        -0.5528516 ,  0.5883466 , -0.4606246 , -0.06202118,  0.26187342,\n",
       "         0.32457367,  0.7335702 ,  0.3925708 , -0.39430422,  0.21815166,\n",
       "         0.507552  ,  0.24462254,  0.04592335,  0.13345616, -0.12200367],\n",
       "       [ 0.05372949,  0.23699877, -0.72665703,  0.20959198, -0.37921444,\n",
       "         0.03314155,  0.6936641 , -0.0411706 ,  0.51279944, -0.17726114,\n",
       "         0.10804163,  0.24417205,  0.32177594,  0.6527193 , -0.00435733,\n",
       "        -0.43116927,  0.19104266,  0.2960647 ,  0.3152053 , -0.37343585,\n",
       "         0.01361017, -0.5840937 , -0.14027278,  0.0232118 ,  0.2142771 ,\n",
       "         0.74627733, -0.24635406,  0.2243491 , -0.1679705 , -0.4126753 ,\n",
       "         0.78151166, -0.63271   , -0.77929133, -0.57505333, -0.7550303 ,\n",
       "        -0.26527995, -0.37601975, -0.20180313, -0.44537887, -0.6992404 ,\n",
       "        -0.47454947,  0.45448953,  0.30768076, -0.05988231, -0.03970312,\n",
       "        -0.05408294,  0.05286335, -0.04831612,  1.1823    ,  0.42542905,\n",
       "         0.05556975, -0.3030563 , -0.17094271,  0.0597505 , -0.3027652 ,\n",
       "        -0.16452956,  0.305381  , -0.3359519 , -1.1972561 ,  0.07526033,\n",
       "         0.01893089,  0.8890578 , -0.05066783, -0.58174855, -0.66157156,\n",
       "         0.27091426,  0.6592773 ,  0.25566757,  0.9800252 ,  0.419001  ,\n",
       "         0.5553136 , -0.04743644, -0.15794566, -0.8675598 , -0.08308289,\n",
       "         0.02384625,  0.42876607,  0.31623664, -0.12228873,  0.19895856,\n",
       "         0.00900458, -0.35655567,  0.18024068, -0.6736576 ,  0.3053822 ,\n",
       "        -0.5528516 ,  0.5883466 , -0.4606246 , -0.06202118,  0.26187342,\n",
       "         0.32457367,  0.7335702 ,  0.3925708 , -0.39430422,  0.21815166,\n",
       "         0.507552  ,  0.24462254,  0.04592335,  0.13345616, -0.12200367]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(LSTM(10, input_shape=(1, embedding_size)))\n",
    "model.add(Dense(1000, input_dim=embedding_size, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(500, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(250, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(embedding_size))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"cosine_proximity\"])\n",
    "# fit network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151323 samples, validate on 64854 samples\n",
      "Epoch 1/1\n",
      "151323/151323 [==============================] - 46s 307us/step - loss: 0.0106 - cosine_proximity: -0.9564 - val_loss: 0.0097 - val_cosine_proximity: -0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161658c4470>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train), epochs=1, batch_size=72, validation_data=(np.array(X_test), np.array(y_test)), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13959762,  0.01631939, -0.41696516,  0.06313697, -0.12622972,\n",
       "        -0.03720687,  0.25855145, -0.08734902,  0.4994015 , -0.2005446 ,\n",
       "        -0.1763522 ,  0.08072495, -0.22234736,  0.11754298, -0.03339034,\n",
       "        -0.38138884,  0.04073703,  0.43529224,  0.20232275, -0.37518978,\n",
       "         0.16817363, -0.57410574, -0.11513245, -0.18778026,  0.40004945,\n",
       "         0.5304459 ,  0.08919945, -0.1270259 ,  0.00998069, -0.16448653,\n",
       "         0.30753332, -0.41158518, -0.23222166,  0.05929966, -0.14071369,\n",
       "        -0.27334884, -0.25098664, -0.04289363, -0.17035541, -0.3736592 ,\n",
       "        -0.28505892, -0.11474848,  0.16708745,  0.27939302, -0.37038994,\n",
       "        -0.18063855,  0.02629133, -0.19152045,  1.0042369 ,  0.04036198,\n",
       "         0.28215742,  0.14667591, -0.27827984,  0.13116273,  0.02519442,\n",
       "        -0.25816816,  0.1905063 , -0.2787228 , -0.5846882 , -0.18519688,\n",
       "         0.00343838,  0.64238465,  0.01729631, -0.09399755, -0.45759088,\n",
       "         0.29964268,  0.22073944, -0.0358572 ,  0.6496969 ,  0.11007833,\n",
       "         0.37095755, -0.23114653,  0.35915524, -0.37330103, -0.54423267,\n",
       "        -0.17105144,  0.14058805,  0.21564938, -0.3504183 , -0.05503404,\n",
       "        -0.22194597, -0.35081977,  0.22844848, -0.11871136,  0.22010794,\n",
       "        -0.53731143,  0.27120164, -0.24033062, -0.28762475,  0.18065552,\n",
       "         0.63794416,  0.28101408,  0.14879301, -0.21439439, -0.13591501,\n",
       "         0.23680384,  0.271199  , -0.05087989,  0.22069196, -0.15474318],\n",
       "       [ 0.19552472, -0.1294585 ,  0.0855248 , -0.01186635, -0.1603043 ,\n",
       "         0.06589475, -0.04149382,  0.06557042,  0.23814294, -0.40097618,\n",
       "        -0.08584927,  0.13858765, -0.1627339 ,  0.10824271,  0.10211798,\n",
       "        -0.14073445,  0.3068018 ,  0.07607989, -0.18055445, -0.68340075,\n",
       "        -0.04943807, -0.53030246, -0.14461717, -0.23072565,  0.54643166,\n",
       "         0.45658273, -0.12883627, -0.10118838,  0.04215429, -0.00381914,\n",
       "         0.21834517, -0.4984034 , -0.38461027,  0.02267711, -0.18453673,\n",
       "        -0.17370048, -0.13645782,  0.23952201, -0.13518772, -0.39147714,\n",
       "        -0.38486275,  0.03040873,  0.12192884, -0.03458077, -0.09515527,\n",
       "         0.07263772, -0.1063282 , -0.12415954,  0.83492684,  0.22954091,\n",
       "         0.17533284,  0.3680594 , -0.2684538 ,  0.16077977,  0.00568849,\n",
       "        -0.00544975,  0.332214  , -0.28969586, -0.72282153, -0.05837156,\n",
       "         0.1372036 ,  0.5069865 ,  0.05687154, -0.2144429 , -0.6594286 ,\n",
       "         0.13306484, -0.018976  , -0.09614737,  0.41364378,  0.10483637,\n",
       "         0.2632925 , -0.24236509,  0.20420265, -0.01301968, -0.20985079,\n",
       "        -0.13880837, -0.1186149 ,  0.1872713 , -0.6055659 ,  0.01085074,\n",
       "        -0.13294187, -0.4345377 ,  0.23486885, -0.18277659,  0.38800848,\n",
       "        -0.36717305,  0.22521523, -0.4277176 , -0.25381327,  0.04684442,\n",
       "         0.5164515 ,  0.2254368 ,  0.09949173, -0.2031073 , -0.28691825,\n",
       "         0.15569982,  0.13385771, -0.13787378,  0.1496143 , -0.04521451]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(X_test)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ht_embedding_table(ht_to_embedding):\n",
    "    '''return table with embeddings and index of ht in table'''\n",
    "    ht_embedding_table = np.ndarray(shape=(len(ht_to_embedding.keys()), embedding_size), dtype=np.float32)\n",
    "    i = 0\n",
    "    idx_to_ht = {}\n",
    "    for ht, em in ht_to_embedding.items():\n",
    "        ht_embedding_table[i] = em\n",
    "        idx_to_ht[i] = ht\n",
    "        i += 1\n",
    "    return ht_embedding_table, idx_to_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht_embedding_table, idx_to_ht = create_ht_embedding_table(ht_to_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_ht_to_prediction(prediction, ht_embedding_table, idx_to_ht):\n",
    "    cosine_sims = (1 -  scipy.spatial.distance.cdist(ht_embedding_table, prediction.reshape(1, -1), 'cosine')).reshape(-1)\n",
    "    max_idx = np.argmax(cosine_sims)\n",
    "    return idx_to_ht[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(ht_embedding_table, idx_to_ht, model, test_embeds):\n",
    "    print(\"Predicting...\")\n",
    "    preds = model.predict(test_embeds)\n",
    "    counter = 0\n",
    "    pred_out = []\n",
    "    print(\"finding closest...\")\n",
    "    for pred in preds:\n",
    "        print(\"\\r{}/{}\".format(counter, len(test_embeds)), end=\"\")\n",
    "        closest_ht = get_closest_ht_to_prediction(pred, ht_embedding_table, idx_to_ht)\n",
    "        pred_out.append((counter, closest_ht))\n",
    "        counter += 1\n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "finding closest...\n",
      "999/1000"
     ]
    }
   ],
   "source": [
    "preds = get_predictions(ht_embedding_table, idx_to_ht, model, test_data_embeds[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_aloc(test_set, test_predictions):\n",
    "    i = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    for prediction in test_predictions:\n",
    "        counter , pred_ht  = prediction\n",
    "        tweet = test_set[counter]\n",
    "        for ht in tweet[\"hashtags\"]:\n",
    "            if pred_ht.lower() in ht.lower():\n",
    "                precision += 1\n",
    "                recall += 1\n",
    "                break\n",
    "    print(precision)\n",
    "       \n",
    "    precision /= len(test_set)\n",
    "    recall /= len(test_set)\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.064"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_aloc(test_data[:1000], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_ht_to_tweet(tweet, ht_embedding_table, idx_to_ht, model):\n",
    "    best_sim = 0\n",
    "    best_ht = \"\"\n",
    "    tweet_embedding = get_embedding_of_tweet(tweet, model)\n",
    "#     for ht, embedding in ht_to_embedding.items():\n",
    "    cosine_sims = (1 -  scipy.spatial.distance.cdist(ht_embedding_table, tweet_embedding.reshape(1, -1), 'cosine')).reshape(-1)\n",
    "    max_idx = np.argmax(cosine_sims)\n",
    "    return idx_to_ht[max_idx]\n",
    "#         if cosine_sim > best_sim:\n",
    "#             best_sim = cosine_sim\n",
    "#             best_ht = ht\n",
    "#     return best_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_expanded_hashtags_preserved.pickle\", 'rb') as f:\n",
    "    data_no_stem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_all_hashtags(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = re.sub(r\"#(\\w+)\", \"\", tweet[\"text\"])\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)        \n",
    "        new_hashtags = tweet[\"hashtags\"]\n",
    "        new_tweets.append({\"text\": tweet_txt.strip().lower(), \"hashtags\": new_hashtags})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_hts = drop_all_hashtags(data_no_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [\"thankgodit'sfriday\"],\n",
       " 'text': 'what fucking absolutely wonderfully delightful friday'}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_hts[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_all_hashtag_symbols(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = re.sub(r\"#\", \"\", tweet[\"text\"])\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)        \n",
    "        new_hashtags = tweet[\"hashtags\"]\n",
    "        new_tweets.append({\"text\": tweet_txt.strip().lower(), \"hashtags\": new_hashtags})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_hts_syms = drop_all_hashtag_symbols(data_no_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_no_hashtags.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_no_hts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_no_hashtag_symbols.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_no_hts_syms, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data_all.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [{'indices': [38, 47], 'text': 'Varshita'}],\n",
       " 'text': \"It's @MarkMasai's acting debut! Watch #Varshita this Saturday and Sunday on @maishamagiceast from 7.30pm to 8.30pm (2 episodes each evening)  Watch: https://t.co/K0Zvjy4IWv\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"slangdict.p\", \"rb\") as f:\n",
    "    slang_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as a friend'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang_dict[\"aaf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter tweets with hashtags between 200 and 500 occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_hashtags(data):\n",
    "    counter = {}\n",
    "    for tweet in data:\n",
    "        hashtags = tweet[\"hashtags\"]\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_text = hashtag[\"text\"].lower()\n",
    "            if hashtag_text in counter:\n",
    "                counter[hashtag_text] = counter[hashtag_text] + 1\n",
    "            else:\n",
    "                counter[hashtag_text] = 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags_counted = count_hashtags(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_golden_middle(hashtags_counted):\n",
    "    '''return the set of hashtags with occurences between 200 and 500'''\n",
    "    golden_middle = set()\n",
    "    for hashtag, occurences in hashtags_counted.items():\n",
    "        if 200 <= occurences <= 500:\n",
    "            golden_middle.add(hashtag)\n",
    "    return golden_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golden_middle = get_golden_middle(hashtags_counted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(golden_middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_200_500_occurences(data, golden_middle):\n",
    "    '''return tweets that contain at least one hashtag with 200-500 occurences'''\n",
    "    tweets = []\n",
    "    for tweet in data:\n",
    "        hashtags = tweet[\"hashtags\"]\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_text = hashtag[\"text\"].lower()\n",
    "            if hashtag_text in golden_middle:\n",
    "                tweets.append(tweet)\n",
    "                break\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_common_hash = filter_200_500_occurences(data, golden_middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1844594"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349278"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_common_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter non asci chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "all_asci = set(string.printable)\n",
    "punctuation = set(\"!%()*+,-.:;<=>?[]\\\\^{}|~\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_non_ascii_punctuation_txt(txt):\n",
    "    return \"\".join(list(filter(lambda x: (x in all_asci) and (x not in punctuation), txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_hashtag_if_left_empty_after_ascii_filtering(tweet):\n",
    "    hashtags = tweet[\"hashtags\"]\n",
    "    tweet_txt = tweet[\"text\"]\n",
    "    hashtags_new = []\n",
    "    for ht in hashtags:\n",
    "        ht_text = filter_non_ascii_punctuation_txt(ht[\"text\"])\n",
    "        if ht_text != \"\":\n",
    "            #if there's something left from the hashtag add it to the new tweet\n",
    "            #also replace its occurence in the tweet text\n",
    "            hashtags_new.append({\"indices\": ht[\"indices\"], \"text\": ht_text})\n",
    "            tweet_txt = tweet_txt.replace(\"#\" + ht[\"text\"], \"#\" + ht_text)\n",
    "        else:\n",
    "            #otherwise delete hashtag from tweet\n",
    "            tweet_txt = tweet_txt.replace(\"#\" + ht[\"text\"], \"\")\n",
    "    return {\"hashtags\": hashtags_new, \"text\": tweet_txt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_hashtags_for_asci_and_punctuation(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        new_tweet = remove_hashtag_if_left_empty_after_ascii_filtering(tweet)\n",
    "        if new_tweet[\"hashtags\"] != []:\n",
    "            new_tweets.append(new_tweet)\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_non_ascii_punctuation(tweet):\n",
    "    txt = tweet[\"text\"]\n",
    "    txt = \"\".join(list(filter(lambda x: (x in all_asci) and (x not in punctuation), txt)))\n",
    "    return {\"hashtags\": tweet[\"hashtags\"], \"text\": txt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_non_ascii({\"text\": \"асд\", \"hashtags\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [{'indices': [64, 85], 'text': 'FreeCommunityCollege'},\n",
       "  {'indices': [92, 103], 'text': 'PreKforAll'}],\n",
       " 'text': 'RT @Kyle_Lierman: During our Obama White House days we proposed #FreeCommunityCollege &amp; #PreKforAll which would have cost $130 billio… '}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_common_hash[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_asci_punct_all_tweets(tweets):\n",
    "    filtered = []\n",
    "    for tweet in tweets:\n",
    "        tweet_filtered = filter_non_ascii_punctuation(tweet)\n",
    "        filtered.append(tweet_filtered)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_filtered_asci_punct = filter_asci_punct_all_tweets(tweets_common_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_filtered_non_empty_hash = filter_hashtags_for_asci_and_punctuation(tweets_filtered_asci_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349278"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_filtered_asci_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346585"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_filtered_non_empty_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @Kyle_Lierman During our Obama White House days we proposed #FreeCommunityCollege &amp #PreKforAll which would have cost $130 billio '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_filtered_non_empty_hash[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blacklist = [\"\\n\", \"\\r\", \"&gt\", \"&amp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An awesome Hoodie for cat lover\\nPRINTED IN THE USA\\nsweaTshirt \\ncatlover \\nHoodie \\nGet yours &gt\\n '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r\"http\\S+\", '', s,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_urls(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        tweet_txt = re.sub(r\"http\\S+\", '', tweet_txt)\n",
    "        new_tweets.append({\"hashtags\": tweet[\"hashtags\"], \"text\": tweet_txt})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_urls = filter_urls(tweets_filtered_non_empty_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [{'indices': [21, 29], 'text': 'Discord'},\n",
       "  {'indices': [30, 40], 'text': 'IndieGame'},\n",
       "  {'indices': [63, 71], 'text': 'GameDev'},\n",
       "  {'indices': [72, 81], 'text': 'IndieDev'},\n",
       "  {'indices': [86, 93], 'text': 'Twitch'},\n",
       "  {'indices': [94, 105], 'text': 'LiveStream'}],\n",
       " 'text': \"I'm the founder of a #Discord #IndieGame community that houses #GameDev/#IndieDev and #Twitch #LiveStream people and #Youtube gamers\\n\\n\\n\\nLet's connect all #Gaming people in one spot join the server today \"}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_urls[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace \\n and \\r \\t with \" \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_special_chars(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        tweet_txt = re.sub(r\"\\r|\\n|\\t\", ' ', tweet_txt)\n",
    "        tweet_txt = re.sub('&amp|&gt','', tweet_txt)\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)\n",
    "        new_tweets.append({\"hashtags\": tweet[\"hashtags\"], \"text\": tweet_txt.strip()})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_special_chars = filter_special_chars(tweets_no_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [{'indices': [64, 85], 'text': 'FreeCommunityCollege'},\n",
       "  {'indices': [92, 103], 'text': 'PreKforAll'}],\n",
       " 'text': 'RT @Kyle_Lierman During our Obama White House days we proposed #FreeCommunityCollege #PreKforAll which would have cost $130 billio'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_special_chars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify hashtag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simplify_tweets(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        hashtags_list = []\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        hashtags = tweet[\"hashtags\"]\n",
    "        for hashtag in hashtags:\n",
    "            hashtags_list.append(hashtag[\"text\"])\n",
    "        new_tweets.append({\"text\": tweet_txt, \"hashtags\": hashtags_list})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_simplified = simplify_tweets(tweets_no_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['FreeCommunityCollege', 'PreKforAll'],\n",
       " 'text': 'RT @Kyle_Lierman During our Obama White House days we proposed #FreeCommunityCollege #PreKforAll which would have cost $130 billio'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_simplified[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find missing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def complete_hashtags(tweets):\n",
    "    new_tweets = []\n",
    "    pat = re.compile(r\"#(\\w+)\")\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        all_hashes = pat.findall(tweet_txt)\n",
    "        new_hashtags = tweet[\"hashtags\"]\n",
    "        for ht in all_hashes:\n",
    "            if ht not in tweet[\"hashtags\"]:\n",
    "                new_hashtags.append(ht)\n",
    "        new_tweets.append({\"text\": tweet_txt, \"hashtags\": new_hashtags})\n",
    "    return new_tweets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_completed = complete_hashtags(tweets_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['FreeCommunityCollege', 'PreKforAll'],\n",
       " 'text': 'RT @Kyle_Lierman During our Obama White House days we proposed #FreeCommunityCollege #PreKforAll which would have cost $130 billio'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_completed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove @s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_relations(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        tweet_txt = re.sub(r\"@(\\w+)\", '', tweet_txt)\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)\n",
    "        new_tweets.append({\"hashtags\": tweet[\"hashtags\"], \"text\": tweet_txt})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_no_monkey_a = filter_relations(tweets_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Discord',\n",
       "  'IndieGame',\n",
       "  'GameDev',\n",
       "  'IndieDev',\n",
       "  'Twitch',\n",
       "  'LiveStream',\n",
       "  'Youtube',\n",
       "  'Gaming'],\n",
       " 'text': \"I'm the founder of a #Discord #IndieGame community that houses #GameDev/#IndieDev and #Twitch #LiveStream people and #Youtube gamers Let's connect all #Gaming people in one spot join the server today\"}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_monkey_a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thalv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncomment this the first time\n",
    "#nltk.download('punkt')\n",
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words_list(sentences):\n",
    "    new_sentences = []\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    for sent in sentences:\n",
    "        words = sent.split(\" \")\n",
    "        filtered_words = [word for word in words if word not in stopwords_set]\n",
    "        if filtered_words != []:\n",
    "            new_sentences.append(\" \".join(filtered_words))\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm founder #Discord #IndieGame community houses #GameDev/#IndieDev #Twitch #LiveStream people #Youtube gamers Let's connect #Gaming people one spot join server today\"]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words_list([\"I'm the founder of a #Discord #IndieGame community that houses #GameDev/#IndieDev and #Twitch #LiveStream people and #Youtube gamers Let's connect all #Gaming people in one spot join the server today\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words_from_tweets(tweets):\n",
    "    new_tweets = []\n",
    "    counter = 1\n",
    "    n = len(tweets)\n",
    "    for tweet in tweets:\n",
    "        print(\"\\r{}/{}\".format(counter, n), end=\"\")\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        tweet_txt_no_stops = remove_stop_words_list([tweet_txt])\n",
    "        \n",
    "        if tweet_txt_no_stops == []:\n",
    "            continue\n",
    "        \n",
    "        hashtags_no_stops = remove_stop_words_list(tweet[\"hashtags\"])\n",
    "        \n",
    "        if hashtags_no_stops == []:\n",
    "            continue\n",
    "        \n",
    "        new_tweets.append({\"text\": tweet_txt_no_stops, \"hashtags\": hashtags_no_stops})\n",
    "        counter += 1 \n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346354/346585"
     ]
    }
   ],
   "source": [
    "tweets_no_stop = remove_stop_words_from_tweets(tweets_no_monkey_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Microsoft', 'Azure', 'Cloud', 'IoT', 'AI', 'IndustrialIoT'],\n",
       " 'text': ['RT #Microsoft Release VMwareFriendly #Azure #Cloud Migrate Service #IoT #AI #IndustrialIoT']}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_stop[10500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346354"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220994\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for tweet in tweets_no_stop:\n",
    "    if tweet[\"text\"][0].startswith(\"RT\"):\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_txt = [tweet[\"text\"] for tweet in tweets_no_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218213"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(only_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_stupidity(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        new_tweets.append({\"text\": tweet[\"text\"][0], \"hashtags\": tweet[\"hashtags\"]})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_stop_1 = fix_stupidity(tweets_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_no_stop = tweets_no_stop_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_duplicates(tweets):\n",
    "    already_seen = set()\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        if tweet[\"text\"] not in already_seen:\n",
    "            already_seen.add(tweet[\"text\"])\n",
    "            new_tweets.append(tweet)\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_duplicates = filter_duplicates(tweets_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218213"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Canucks'],\n",
       " 'text': \" There's buyers trade market right people may projected #Canucks sellers right view buyers\"}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_duplicates[10050]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove RT symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something something RT'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"^RT \", '', \"RT something something RT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_rt(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = tweet[\"text\"]\n",
    "        tweet_txt = re.sub(r\"^RT \", '', tweet_txt)\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)\n",
    "        new_tweets.append({\"hashtags\": tweet[\"hashtags\"], \"text\": tweet_txt.strip()})\n",
    "    return new_tweets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_rt = remove_rt(tweets_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_txt = [tweet[\"text\"] for tweet in tweets_no_rt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_no_duplicates = filter_duplicates(tweets_no_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216259"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Discord',\n",
       "  'IndieGame',\n",
       "  'GameDev',\n",
       "  'IndieDev',\n",
       "  'Twitch',\n",
       "  'LiveStream',\n",
       "  'Youtube',\n",
       "  'Gaming'],\n",
       " 'text': \"I'm founder #Discord #IndieGame community houses #GameDev/#IndieDev #Twitch #LiveStream people #Youtube gamers Let's connect #Gaming people one spot join server today\"}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_duplicates[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write this version down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_no_expand_hashtags_preserved.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_no_duplicates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_slang_txt(txt):\n",
    "    words = txt.split(\" \")\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.lower() in slang_dict:\n",
    "            new_words.append(slang_dict[word.lower()].lower())\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ripped', 'whatafuckingloser']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_slang_hashtags([\"Ripped\", \"WAFL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_slang_hashtags(hashtags):\n",
    "    new_hashtags = []\n",
    "    for hashtag in hashtags:\n",
    "        if hashtag.lower() in slang_dict:\n",
    "            new_hashtags.append(slang_dict[hashtag.lower()].lower().replace(\" \", \"\"))\n",
    "        else:\n",
    "            new_hashtags.append(hashtag)\n",
    "    return new_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expand_slang(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = expand_slang_txt(tweet[\"text\"])\n",
    "        hashtags = expand_slang_hashtags(tweet[\"hashtags\"])\n",
    "        \n",
    "        new_tweets.append({\"hashtags\": hashtags, \"text\": tweet_txt})\n",
    "    return new_tweets      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_slang_expanded = expand_slang(tweets_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['UX', 'knowledge'],\n",
       " 'text': 'Today #UX Team Leader sharing #knowledge'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_slang_expanded[11231]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"no_stem_expanded_hashtags_preserved.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_slang_expanded, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_txt(ps, txt):\n",
    "    words = txt.split(\" \")\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(ps.stem(word))\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_hashtags(ps, hts):\n",
    "    new_hts = []\n",
    "    for ht in hts:\n",
    "        new_hts.append(ps.stem(ht))\n",
    "    return new_hts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tweets(tweets):\n",
    "    new_tweets = []\n",
    "    ps = PorterStemmer()\n",
    "    counter = 1\n",
    "    for tweet in tweets:\n",
    "        print(\"\\r{}/{}\".format(counter, len(tweets)), end=\"\")\n",
    "        tweet_txt = stem_txt(ps, tweet[\"text\"])\n",
    "\n",
    "        new_tweets.append({\"hashtags\": tweet[\"hashtags\"], \"text\": tweet_txt})\n",
    "        counter += 1\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216259/216259"
     ]
    }
   ],
   "source": [
    "tweets_stemmed = stem_tweets(tweets_slang_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216259"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Discord',\n",
       "  'IndieGame',\n",
       "  'GameDev',\n",
       "  'IndieDev',\n",
       "  'Twitch',\n",
       "  'LiveStream',\n",
       "  'Youtube',\n",
       "  'Gaming'],\n",
       " 'text': \"i'm founder #discord #indiegam commun hous #gamedev/#indiedev #twitch #livestream peopl #youtub gamer let' connect #game peopl one spot join server today\"}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_stemmed[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"all_preproc_hashtags_preserved.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_stemmed, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_all_hashtags(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = re.sub(r\"#(\\w+)\", \"\", tweet[\"text\"])\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)        \n",
    "        new_hashtags = tweet[\"hashtags\"]\n",
    "        new_tweets.append({\"text\": tweet_txt, \"hashtags\": new_hashtags})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_hashtags = drop_all_hashtags(tweets_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Discord',\n",
       "  'IndieGame',\n",
       "  'GameDev',\n",
       "  'IndieDev',\n",
       "  'Twitch',\n",
       "  'LiveStream',\n",
       "  'Youtube',\n",
       "  'Gaming'],\n",
       " 'text': \"i'm founder commun hous / peopl gamer let' connect peopl one spot join server today\"}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_hashtags[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"all_preproc_no_hashtags.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_no_hashtags, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtags no symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_all_hashtag_symbols(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        tweet_txt = re.sub(r\"#\", \"\", tweet[\"text\"])\n",
    "        tweet_txt = re.sub(' +',' ', tweet_txt)        \n",
    "        new_hashtags = tweet[\"hashtags\"]\n",
    "        new_tweets.append({\"text\": tweet_txt, \"hashtags\": new_hashtags})\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_no_ht_symbols = drop_all_hashtag_symbols(tweets_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': ['Discord',\n",
       "  'IndieGame',\n",
       "  'GameDev',\n",
       "  'IndieDev',\n",
       "  'Twitch',\n",
       "  'LiveStream',\n",
       "  'Youtube',\n",
       "  'Gaming'],\n",
       " 'text': \"i'm founder discord indiegam commun hous gamedev/indiedev twitch livestream peopl youtub gamer let' connect game peopl one spot join server today\"}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_ht_symbols[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"all_preproc_no_ht_symbols.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets_no_ht_symbols, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
